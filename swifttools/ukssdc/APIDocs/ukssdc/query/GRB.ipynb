{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c874cdd",
   "metadata": {},
   "source": [
    "# The `swifttools.ukssdc.query.GRB` class\n",
    "\n",
    "The `GRBQuery` class is a child class of the [`swifttools.ukssdc.query` class](../query.ipynb) extending its functionality to give some GRB-specific options. It makes use of the [`swifttools.ukssdc.data.GRB` module](../data/GRB.ipynb) to allow you to download GRB data products for objects found by querying.\n",
    "\n",
    "This combination of features means that you can now very easily carry out tasks such as downloading all XRT light curves for GRBs with T90&lt;2 s - something many people have requested.\n",
    "\n",
    "In this guide I am going to cover the GRB-specific query features and show you some examples of how to get data, but I am not going into all the details of the generic query syntax, or the product access functions. For those I refer you to the [`query`](../query.ipynb) and [`data.GRB`](../data/GRB.ipynb) documentation.\n",
    "\n",
    "First we will import the module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ad30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifttools.ukssdc.query as uq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa313c3",
   "metadata": {},
   "source": [
    "## Page contents\n",
    "\n",
    "* [The `GRBQuery` class](#grbquery)\n",
    "* [The catalogues](#cats)\n",
    "* [Combining catalogues](#aux)\n",
    "* [GRB Products](#prods)\n",
    "  * [Light curves](#curves)\n",
    "  * [Spectra](#spectra)\n",
    "  * [Burst analyser](#ban)\n",
    "  * [Positions](#positions)\n",
    "  * [Obs data](#data)\n",
    "\n",
    "----\n",
    "\n",
    "<a id='grbquery'></a>\n",
    "## The `GRBQuery` class\n",
    "\n",
    "For querying the GRB catalogues we use the `GRBQuery` class. We can create an object of this just like [we did for `ObsQuery`](../query.ipynb#obsquery):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3e2ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = uq.GRBQuery(silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc8624a",
   "metadata": {},
   "source": [
    "I've again set `silent=False` as for interactive, and especially pedagogical use, this is helpful.\n",
    "\n",
    "Whereas for `ObsQuery` we had a choice of which table in the catalogue we wanted to query, for `GRBQuery` the situation is slightly different, we have to first choose which GRB catalogue we want to query. At the present time, there is only one table in each catalogue, so this effectively replaces the table controls we saw for `ObsQuery`. Before we go any further, I should introduce these catalogues.\n",
    "\n",
    "\n",
    "<a id='cats'></a>\n",
    "## The catalogues\n",
    "\n",
    "There is only one GRB catalogue produced by the UKSSDC, and this is limited to GRB data. However, as there has been (much!) demand for a way to access XRT products for samples derived from other information, I've provided tools to use two other catalogues provided by [the SDC](https://swift.gsfc.nasa.gov) as well. So, the `GRBQuery` module lets use select the following catalogues:\n",
    "\n",
    "* [The live XRT GRB catalogue](https://www.swift.ac.uk/xrt_live_cat) \"UK_XRT\"\n",
    "* [The SDC Data Table](https://swift.gsfc.nasa.gov/archive/grb_table.html/) \"SDC_GRB\"\n",
    "* [The Swift/BAT GRB catalog](https://swift.gsfc.nasa.gov/results/batgrbcat/) \"SDC_BAT\"\n",
    "\n",
    "The labels at the end of each row above are the names by which these catalogues are accessed, as you'll see in a moment.\n",
    "\n",
    "Because the SDC tables are provided externally (i.e. by the SDC), in order to fit them nicely into my API back end, I have actually set up CRON jobs that run hourly to download the latest versions from the above sources and ingest them into my own database system. This means that there is always the possibility that things are slightly out of sync, but never by more than an hour. I also created the metadata myself, so any errors therein are entirely my own fault.\n",
    "\n",
    "There are also a couple of warnings and caveats related to these tables.\n",
    "\n",
    "The Swift Data Table is curated by JD Myers at GSFC, and is essentially manually compiled from information contained in GCN circulars. This has presented the occasional challenge ingesting everything into a form that can be queried by this API. For example, how will a T90 value of \"~2\" fare with a \">\" operator? To resolve this, I strip out the non-numeric characters from columns like this, and set some warning columns [which we will look at presently](#dtcaveat).\n",
    "\n",
    "The BAT GRB catalogue is a machine-readable catalogue without these issues and so is just ingested directly, but again there a couple of warnings. First and most importantly, at the time of writing the catalogue only includes GRBs up to the end of 2023. Secondly, when I ingested that table I found a couple of GRBs with duplicate rows; only the first row is ingested ('name' is required as a unique column for combining catalogues).\n",
    "\n",
    "Right, with those preliminaries out of the way, let's get to business.\n",
    "\n",
    "Managing which catalogue we are querying is directly analogous to managing tables, except that we replace \"table\" with \"cat\". So (in case you didn't to it above) let's create a query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee80ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = uq.GRBQuery(silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6292639",
   "metadata": {},
   "source": [
    "And then find out which catalogue was selected by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0b4d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a2a0df",
   "metadata": {},
   "source": [
    "I listed all of the catalogues above, but you can get their labels directly from the class too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2af103",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.cats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cb2c1d",
   "metadata": {},
   "source": [
    "We can change catalogue in two ways, either changing the cat variable, or supplying it to the constructor. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85821b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = uq.GRBQuery(cat='BAT_GRB',\n",
    "                silent=False)\n",
    "q.cat = 'SDC_GRB'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f722a63",
   "metadata": {},
   "source": [
    "So in the above I created a query using the BAT GRB catalogue, and then decided I actually wanted the SDC data table catalogue instead.\n",
    "\n",
    "You may be wondering why this is a catalogue and not a \"table\", whereas in the `ObsQuery` case we used tables. The answer is that the `query` module actually has both, and the heirarchy is `catalogue` -> `tables`. In the `ObsQuery` module we have a single catalogue that has multiple tables; in this case we have multiple catalogues that each have (at present) a single table. [The `SXPSQuery` class](SXPS.ipynb) contains multiple catalogues with multiple tables each.\n",
    "\n",
    "Of course, we can jump right in with a simple query now, but I'm guessing you're not often going to want to select GRB data by a cone search and so the 'advanced' method will be more useful, and for that you will probably want to check out the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9483f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066bbb21",
   "metadata": {},
   "source": [
    "Here I've shown the metadata for the SDC Data Table, and slightly annoyingly, Jupyter compresses the output. You can explore it yourself of course, or we can just extract the 'ColName' data, i.e. what columns does the SDC Data Table supply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b807a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(q.metadata['ColName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215efd6f",
   "metadata": {},
   "source": [
    "<a id='dtcaveat'></a>\n",
    "### SDC data table caveats\n",
    "\n",
    "For the \"SDC_GRB\" table used above there are some caveats which I've alluded to above - some fields in the original table cannot be directly ingested into my database. The columns ending '\\_warn' and '\\_orig' which you can see above tell us when that happened. Any time a field cannot be ingested 'as is' (for example a numerical field that contained a non-numerical character), then the '\\_warn' column for that row is set to `True` and the '\\_orig' field is populated - this is a text field containing the original string. So, for example, if there was a problem with \"BAT_T90\" then the \"BAT_T90\" column will be replaced with my code's \"best guess\" as to the correct numerical value, \"BAT_T90_orig\" will be set to the original value, and \"BAT_T90_warn\" will be 1.\n",
    "\n",
    "The last 4 columns listed in the metadata are summaries, they tell you if any warnings related to each instrument, or any warnings at all, were set. So one may, for example, want to filter out such rows, either in the query or after getting the results. Let's take a moment to explore this just a bit more.\n",
    "\n",
    "First, we'll get all the data for a query and then filter it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed62ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.addFilter(('BAT_T90', '<', 2))\n",
    "q.addCol('*')\n",
    "q.submit()\n",
    "q.results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723684d0",
   "metadata": {},
   "source": [
    "I could now define a subset of only those with no BAT_T90_warning value set, so I only have the cases that definitely match my query. Subsets were [discussed in the `ObsQuery` documentation](../query.ipynb#subsets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea10980",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset=q.results['BAT_T90_warn'] is False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16f1bdc",
   "metadata": {},
   "source": [
    "(Pythonic note, you must use `== False` here, `is False` will not give the correct result).\n",
    "\n",
    "I could pass this subset to any of the product functions that we will come to later, or just take a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035c2151",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.results.loc[subset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568d44d4",
   "metadata": {},
   "source": [
    "This only has one fewer row than the original query. It may be more informative to look at that row, so lets find the row which did have the warning set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset=q.results['BAT_T90_warn'] is True\n",
    "myFrame = q.results.loc[subset]\n",
    "myRow = myFrame.iloc[0]\n",
    "print(myRow['Name'])\n",
    "print(myRow['BAT_T90'])\n",
    "print(myRow['BAT_T90_orig'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75fd4ed",
   "metadata": {},
   "source": [
    "Here you can see the problem: GRB 161004A has a T90 value in the SDC_GRB table of \"~1.3 to ~3\". Since I want T90 to be a number, my ingestion code took \"1.3\" but set the warning flag. \n",
    "\n",
    "How you choose to handle such cases is entirely up to you, and depends on your specific needs; all I'm trying to do here is to show you the tools I have provided to help you in this.\n",
    "\n",
    "<a id='aux'></a>\n",
    "## Combining catalogues\n",
    "\n",
    "While all of these catalogues are, in themselves, great, I think we're often going to want to select GRBs using data from multiple catalogues. For example, maybe you want to get all short GRBs with at least one break in their XRT light curve, or something like that. In this case, we're going to have to combine the catalogues. And for this purpose the `GRBQuery` class includes the concept of auxilliary catalogues. The premise here is very simple: you define a `GRBQuery` and select the catalogue to query on, I will call this the 'primary catalogue'. Then you can add a second catalogue, which we call the 'auxilliary catalogue'. Then you define filters and submit, and the only results returned will be those which met the criteria in both catalogues.\n",
    "\n",
    "As always an example teaches better than my blethering, so let's do exactly what I just said, get all GRBs with T90<2 and at least one break in their XRT light curve fit.\n",
    "\n",
    "I'm going to use the BAT GRB catalogue for T90 (even though it stops in 2020) for this demo and I'll make that the primary catalogue, although which is primary and which auxilliary makes very little difference.\n",
    "\n",
    "First up, let's create a query object for the primary catalogue. As ever for the demos, I'll turn off silent mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4bf787",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = uq.GRBQuery(cat='BAT_GRB',\n",
    "                silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddc893e",
   "metadata": {},
   "source": [
    "Now I will add the XRT catalogue as be an auxilliary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd142e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.setAuxCat('UK_XRT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6faccf4",
   "metadata": {},
   "source": [
    "`setAuxCat()` requires a catalogue  name, and optionally `silent` and `verbose`; if these latter are not specified, they are set to the values of the primary catalogue.\n",
    "\n",
    "The auxilliary catalogue is literally just another `GRBQuery` object, and we can access it via `q.auxCat` so anything we can do to the primary catalogue we can also do to the auxilliary catalogue. This is handy because we need to add filters to both.\n",
    "\n",
    "**Important note** filters must be added to the correct catalogue; I have not made a mechanism to infer from the column name which catalogue you meant, because it is possible for both catalogues to share column names. So it is your reponsibility to get the right filters in the right place. \n",
    "\n",
    "So, let's do that. FIrst we want a T90 filter, which applies to our primary catalogue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.addFilter(('T90', '<', 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9da3954",
   "metadata": {},
   "source": [
    "and we want a filter on the number of light curve breaks for the auxilliary catalogue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85468280",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.auxCat.addFilter( ('NumLCBreaks', '>=', 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4816a953",
   "metadata": {},
   "source": [
    "If you're wondering what the filter syntax should be, or how I knew the names of the columns to filter on, you should read the [top-level `query` documentation](../query.ipynb) which explains both of these things.\n",
    "\n",
    "Now we can submit the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c130d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c0c948",
   "metadata": {},
   "source": [
    "Because we had `silent=False` you can see that there were two queries done, and they received different number of rows, however:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ed34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(q.results))\n",
    "print (len(q.auxCat.results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175632a1",
   "metadata": {},
   "source": [
    "You can also see that the results - of both catalogues - have been filtered to contain only matches. By default, the results are kept separate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbfd382",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914ca23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.auxCat.results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22702c9",
   "metadata": {},
   "source": [
    "We can merge these into a single table. This will change `q.results` (but not `q.auxCat.results`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193bede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.mergeResults()\n",
    "\n",
    "q.results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57390794",
   "metadata": {},
   "source": [
    "We could actually have done this at submit time if we wanted, let's redo the query and demonstrate that. I can't run `submit` again without unlocking or resetting the query. I'll reset it and show you a couple of things while I'm here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b441da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.reset(keepAux=True, keepFilters=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3962be2e",
   "metadata": {},
   "source": [
    "This reset the query, but kept all my filters and the auxilliary catalogue (although that too was reset). If I'd also defined which columns to retrieve I could have kept them using the `keepCols` argument.\n",
    "\n",
    "For our new query, let's request all columns in both catalogues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40514d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.addCol('*')\n",
    "q.auxCat.addCol('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.submit(merge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924cca49",
   "metadata": {},
   "source": [
    "Note that this time I gave `merge=True`, so we should have merged the results already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2eefb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6db6e7b",
   "metadata": {},
   "source": [
    "And indeed we have. I know Jupyter is truncating the output, but I also know that `Trig_ID` is a BAT_GRB column and `Onboard_Decl_apy` is from the UK_XRT catalogue, so I can see that it worked. Oh and by the way, do note that as for ObsQuery, for all the RA/Dec columns we have `_s` (=sexagesimal) and `_apy` (=astropy) columns created for us.\n",
    "\n",
    "That's really the bulk of auxilliary catalogues and queries covered. I didn't cover cone searches because they are so simple and covered in the [`ObsQuery` tutorial](../query.ipynb); all I will add is that if you run `q.addConeSearch()` to a query with an auxCat then the cone search will be automatically applied to the aux cat as well *provided you've already added the aux cat*. Essentially I always advise that the very first things you do are create your query and add an auilliary catalogue if you need to, and then add filters etc.\n",
    "\n",
    "Lastly, since the `auxCat` is itself just a `GRBQuery` object, it too can have an `auxCat`. So you can query by combining all three catalogues if you want (i.e. `q.auxCat.setAuxCat()`), although I haven't tested this. One note of warning for this: when you add an auxilliary catalogue you will be prevented from choosing the same catalogue as the primary one. If you try to add a third layer you can actually use the primary catalogue again. i.e. you could have XRT_UK -> BAT_GRB -> XRT_UK. If you do this, you deserve whatever happens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcb2bbd",
   "metadata": {},
   "source": [
    "<a id='prods'></a>\n",
    "## GRB Products\n",
    "\n",
    "Having identified a sample of GRBs, we may want to actually get at some of the data - recall my example above where I've been asked for the ability to *download all XRT light curves* for GRB with T90&lt;2 s. \n",
    "\n",
    "This is easy to do, because the `GRBQuery` class provides wrappers to all of the [`swifttools.ukssdc.data.GRB` functions](../data/GRB.ipynb). As [already explained for `ObsQuery`](../query.ipynb#prods), the syntactic difference is just that we don't provide the list of objects to retrieve, that is automatically taken from `q.results`, but we can provide [a subset](../query.ipynb#subsets) of rows.\n",
    "\n",
    "I also remind you that I am *not* going to spend ages detailing all the different options available for downloading products and what they do. I did it in the [`data.GRB` documentation](../data/GRB.ipynb) so you can refer to that for details.\n",
    "\n",
    "The other thing to remind you is that by default all of the functions to get data (starting `get`), when called via the `query` module, neither save data to disk nor return it, but save it in a variable inside your `GRBQuery` object. You can change this behaviour with the `saveData` and `returnData` arguments, but even then, the data will still be stored in class variables. I will introduce those variables to you in a moment, but first let me tell you something about them. They are always  `dict`s with one key per object in your query results, even if there was only one object found. You can decide whether the key is the GRB name or targetID by specifying **one** of `byName=True` or `byID=True` (if you specify neither, name is assumed). Of course, your results must include the specified column.\n",
    "\n",
    "So, the basic syntax of every product retrieval function is the same:\n",
    "\n",
    "`q.get<something>(byID, byName, subset, returnData, saveData, **kwargs)`\n",
    "\n",
    "where `**kwargs` are any arguments you want to pass to the underlying function in [`data.GRB`](../data/GRB.ipynb).\n",
    "\n",
    "So, let's run some demos. We'll stick with the query above, but I'll repeat the cells here in case you haven't run them or have been doing your own editing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0468c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = uq.GRBQuery(cat='BAT_GRB',\n",
    "                silent=False)\n",
    "q.setAuxCat('UK_XRT')\n",
    "q.addFilter(('T90', '<', 2))\n",
    "q.auxCat.addFilter( ('NumLCBreaks', '>=', 1))\n",
    "q.submit(merge=True)\n",
    "print(f\"\\n\\nI have {len(q.results)} rows in the merged table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e0210a",
   "metadata": {},
   "source": [
    "<a id='curves'></a>\n",
    "### Light curves\n",
    "\n",
    "Let's open up just by getting light curves for everything. And I'll index them by targetID instead of name because why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9128f90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.getLightCurves(incbad=True, byID=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481cf639",
   "metadata": {},
   "source": [
    "I added `incbad` just to prove that `**kwargs` works.\n",
    "\n",
    "As you should have antipicated, nothing was returned by the function and nothing written to disk. Our light curve data is in our `q` object, in a variable called, oddly enough, `lightCurves`. As I've explained a moment ago, this should be a `dict` with one entry for each of the 16 GRBs matching our query, and each of those should be a [light curve `dict`](https://www.swift.ac.uk/API/ukssdc/structures.md#the-light-curve-dict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efc8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(q.lightCurves.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c9de5c",
   "metadata": {},
   "source": [
    "That looks about right, except the strange entry of '0', but actually (I checked this) one of the GRBs in the BAT table did have a triggerID of 0. I don't know why, but there you are. There is no light curve for this object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a630a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.lightCurves[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b65ef6b",
   "metadata": {},
   "source": [
    "so we will chalk this one up as a mystery and move on.\n",
    "\n",
    "The other entries are standard light curve `dict`s as expected, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5659d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(q.lightCurves[821103].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0cf819",
   "metadata": {},
   "source": [
    "If we call `getLightCurves` again it will combine the results with this `dict`, so imagine I realise I wanted the non-\"incbad\" data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cfa951",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.getLightCurves(incbad=False, byID=True)\n",
    "list(q.lightCurves[821103].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd65d17f",
   "metadata": {},
   "source": [
    "and you can see that the light curve `dict` has been updated.\n",
    "\n",
    "We can also completely forget the light curves with `clearLightCurves()`, so let's do that and just check what happens if we supply no arguments to `getLightCurves()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2aa03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.clearLightCurves()\n",
    "q.getLightCurves()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e836ff",
   "metadata": {},
   "source": [
    "Given that I didn't supply `byID` or `byName` what has happened? Let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57329f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(q.lightCurves.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebdba28",
   "metadata": {},
   "source": [
    "For me, I see GRB names in the list above, **I can't guarantee that you will see the same** there is no default set so what you see depends on how your Python executable traverses the internal data. For the following examples I'm assuming the results are indexed by name, so if yours are not, then run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7025a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.clearLightCurves()\n",
    "q.getLightCurves(byName=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4fad49",
   "metadata": {},
   "source": [
    "(By the way, all those \"Resolved\" lines, which are suppressed if `silent=True` are just because you are getting the GRBs by name, but on the UKSSDC they are indexed by targetID, so some look ups are being done.)\n",
    "\n",
    "#### Saving light curves\n",
    "\n",
    "Although the default behaviour of the `query` module is to save data to an internal variable, we can still save it to disk. One way would be to say `saveData=True`, and then pass all the arguments like `destDir` etc. This was covered in detail in the [the `data.GRB` notebook](../data/GRB.ipynb#lightcurves), so you can read that if you want to know how.\n",
    "\n",
    "The query module also lets us save the light curves after downloading. Again, this is very similar to the `data` module, except that we have an extra argument: `whichGRBs`. This optional argument takes a list/tuple of the light curves in our `q.lightCurves` variable, and lets us save only some of the downloaded curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e260b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.saveLightCurves(whichGRBs=['GRB 051221A', 'GRB 100117A'],\n",
    "                  destDir='/tmp/APIDemo_GRB_LC',\n",
    "                  header=True,\n",
    "                  subDirs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27723be3",
   "metadata": {},
   "source": [
    "#### Plotting light curves\n",
    "\n",
    "You can also plot light curves, using the [module-level `plotLightCurve()` function](https://www.swift.ac.uk/API/ukssdc/commonFunc.md#plotlightcurve), but because I'm really nice, and you really want to buy me a drink, I've added a `plotLightCurves()` function into this module to wrap around it - although it still only plots one LC at a time. \n",
    "\n",
    "\n",
    "If we don't try to specify the datasets to plot, we may end up in a mess (or at least, with a really messy plot), so let's pick a GRB and check what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.lightCurves['GRB 060313']['Datasets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc7669b",
   "metadata": {},
   "source": [
    "OK, now let's plot this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32555148",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.plotLightCurves('GRB 060313',\n",
    "                  whichCurves=('WT_incbad', 'PC_incbad', 'PCUL_incbad'),\n",
    "                  xlog=True,\n",
    "                  ylog=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00f3691",
   "metadata": {},
   "source": [
    "As noted in the [`plotLightCurve()` documentation](https://www.swift.ac.uk/API/ukssdc/commonFunc.md#plotlightcurve), it returns the pyplot `fig` and `ax` objects, and can receive them as well, which means we can add extra light curves to the same plot. So, let's repeat the above (capturing the return) and then we'll add a second light curve:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c040d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = q.plotLightCurves('GRB 060313',\n",
    "                       whichCurves=('WT_incbad', 'PC_incbad', 'PCUL_incbad'),\n",
    "                       xlog=True,\n",
    "                       ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb02172",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = q.plotLightCurves('GRB 160501A',\n",
    "                       whichCurves=('WT_incbad', 'PC_incbad', 'PCUL_incbad'),\n",
    "                       xlog=True,\n",
    "                       ylog=True,\n",
    "                       fig = f,\n",
    "                       ax = a,\n",
    "                       cols = {'WT':'cyan', 'PC': 'magenta'}\n",
    "                       )\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e78646",
   "metadata": {},
   "source": [
    "For reasons I don't entirely follow, if the above cell doesn't end with the `f` (i.e. just the `matplotlib.figure` object, Jupyter doesn't plot it. \n",
    "\n",
    "Notice above I made use of the `cols` argument to make the second GRB use difference colours to the first.\n",
    "\n",
    "The purpose of `plotLightCurve()` and its wrappers is, however, not to give you the perfect plotting function to do anything you want; it's there to give an easy and quick way of plotting light curves, so you can have a look at what's going on. If you want to do anything beyond this then you'll need to write your own functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92e97b5",
   "metadata": {},
   "source": [
    "<a id='spectra'></a>\n",
    "### Spectra\n",
    "\n",
    "This will shock you I'm sure, but to get spectra we replace the word 'lightCurves' in the above example with 'spectra'. I know, outrageous, right? Let's throw in a subset just to justify this being a separate example, and I'll also remind you how `saveData` works because that is how nice I am."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b57988",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.getSpectra(subset=q.results['Err90']<1.9,\n",
    "            saveData=True,\n",
    "            destDir='/tmp/APIDemo_GRB_Spec2',\n",
    "            extract=False,\n",
    "            removeTar=False,\n",
    "            saveImages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c20c12",
   "metadata": {},
   "source": [
    "This function has done a few things. Firstly, it only got spectra for rows where the \"Err90\" column was less than 1.9&dagger;.\n",
    "\n",
    "Secondly, it saved the spectral data for those objects, in the form of `tar` files and images, to '/tmp/APIDemo_GRB_Spec2', but it neither extracted the `tar` files nor deleted them. And lastly, it saved the spectral data to the internal variable `q.spectra` (this last point was not requested explicitly, it *always* happens). \n",
    "\n",
    "(&dagger; To find out what Err90 is, you'd have to read the metadata, or in this case, the auxCat metadata. To save you the bother: it's the XRT 90% confidence radial position error, in arcsec.)\n",
    "\n",
    "Let's check out that variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(q.spectra.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c66d14",
   "metadata": {},
   "source": [
    "Each of these will contain a [spectrum `dict`](https://www.swift.ac.uk/API/ukssdc/structures.md#the-spectrum-dict) and we explored that in the [`data.GRB` documentation](../data/GRB.ipynb#spectra) so I'm not repeating it here.\n",
    "\n",
    "As with lightcurves, we can save the data after downloading as well, specifying which GRBs to save if we wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.saveSpectra(destDir='/tmp/APIDemo_GRB_Spec3',\n",
    "              whichGRBs=('GRB 051221A', 'GRB 060218', 'GRB 060313', 'GRB 061201',),\n",
    "              extract=True,\n",
    "              removeTar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa3d27",
   "metadata": {},
   "source": [
    "<a id='ban'></a>\n",
    "### Burst analyser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6533fe98",
   "metadata": {},
   "source": [
    "Honestly, nothing about this should be difficult or surprising. Again, all the arguments available to [`data.GRB.getBurstAnalyser()`](../data/GRB.ipynb#ban) exist and the wrapper in this class works just like those above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c90bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.getBurstAnalyser(subset=q.results['Err90']<1.5,\n",
    "                   downloadTar=True,\n",
    "                   extract=False,\n",
    "                   removeTar=False,\n",
    "                   destDir='/tmp/APIDemo_GRB_burstAn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef54a8fc",
   "metadata": {},
   "source": [
    "This time I got the results only for things with Err90 below 1.5 (arcsec), and again, saved them to disk. And as you should be aware, the data, in the form of [a burst analyser `dict`](https://www.swift.ac.uk/API/ukssdc/structures.md#the-burst-analyser-dict), were also saved into a class variable whose name I'm sure you can hazard a guess at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5381f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.burstAnalyser.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b324d117",
   "metadata": {},
   "source": [
    "And again, we can also save data having downloaded it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074f1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.saveBurstAnalyser(destDir=\"/tmp/APIDemo_GRB_burstAn2\",\n",
    "                    whichGRBs=['GRB 060218', 'GRB 200324A'],\n",
    "                    header=True,\n",
    "                    subDirs=True,\n",
    "                    usePropagatedErrors=True,\n",
    "                    instruments=['XRT',]\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f11434",
   "metadata": {},
   "source": [
    "<a id='pos'></a>\n",
    "### Positions\n",
    "\n",
    "GRB positions differ only from the above examples by the fact that there is no `saveData` option. If I'm honest, I don't know why you may want to get positions for GRBs returned by a query, because they are already in the 'UK_XRT' catalogue, so you can just return those columns, but hey, I'm not here to judge (much):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d45e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.getPositions(byName=True, subset=q.results['Image_position_err']>1.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d21dfab",
   "metadata": {},
   "source": [
    "This time I made a subset based on the BAT image position error (in arcmin) just for fun, and I got 5 results. These were saved in (can you guess?) `q.positions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3e924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.positions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3418fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.positions['GRB 060218']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcfbb8b",
   "metadata": {},
   "source": [
    "Before moving on let me use positions, as they are small, to show one other thing I mentioned but haven't demostrated: all of this `get` functions can take `returnData=True`, to return the data as well as storing it internally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c24a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointlessVar = q.getPositions(byName=True,\n",
    "                              subset=q.results['Image_position_err']>1.8,\n",
    "                              returnData=True)\n",
    "pointlessVar.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acbc79a",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "### Obs Data\n",
    "\n",
    "And finally, you may want to download all of the obsData for your result. In this demo I will literally only get one GRB, to speed things up a bit. This is the one `get` function that sets no interval variable, it only saves data to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.getObsData(destDir=\"/tmp/APIDemo_GRBdata\",\n",
    "             subset=q.results['GRBname']=='GRB 200324A',\n",
    "             instruments=['XRT',],\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69e969c",
   "metadata": {},
   "source": [
    "## And last\n",
    "\n",
    "If you're wondering where the options to rebin light curves or time-slice spectra are then I'm afraid you're going to be disappointed. Making it easy for you to (deliberately or accidentally) request time-sliced spectra for 1,500 GRBs is not something I want to do -- we do, after all, have a finite compute load. However, it should be pretty easy for you to write a code to loop over your results and submit such jobs, one or two at a time. I would do it now as a demo, but I'm not *that* nice :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
